# üìä Modelos Ollama - Capacidad del Servidor

## üñ•Ô∏è Recursos Disponibles

- **RAM Total**: 15GB
- **RAM Disponible**: ~13GB (despu√©s de servicios base)
- **CPU**: 8 cores
- **Modelo Actual**: llama3:latest (4.7GB)

---

## üìã Modelos Ollama Disponibles y Requisitos

### Modelos Peque√±os (7B par√°metros)

| Modelo | Tama√±o | RAM Necesaria | Estado |
|--------|--------|---------------|--------|
| **llama3:8b** | ~4.7GB | ~6-8GB | ‚úÖ **Instalado** |
| **mistral:7b** | ~4.1GB | ~6-8GB | ‚úÖ Viable |
| **codellama:7b** | ~3.8GB | ~6-8GB | ‚úÖ Viable |
| **qwen:7b** | ~4.3GB | ~6-8GB | ‚úÖ Viable |

### Modelos Medianos (13B par√°metros)

| Modelo | Tama√±o | RAM Necesaria | Estado |
|--------|--------|---------------|--------|
| **llama3.1:8b** | ~4.7GB | ~6-8GB | ‚úÖ Viable |
| **mistral:13b** | ~7.2GB | ~10-12GB | ‚ö†Ô∏è **L√≠mite** |
| **codellama:13b** | ~7.1GB | ~10-12GB | ‚ö†Ô∏è **L√≠mite** |
| **qwen:14b** | ~7.8GB | ~10-12GB | ‚ö†Ô∏è **L√≠mite** |

### Modelos Grandes (70B par√°metros)

| Modelo | Tama√±o | RAM Necesaria | Estado |
|--------|--------|---------------|--------|
| **llama3:70b** | ~40GB | ~48-50GB | ‚ùå **No viable** |
| **mistral:70b** | ~39GB | ~48-50GB | ‚ùå **No viable** |
| **qwen:72b** | ~41GB | ~48-50GB | ‚ùå **No viable** |

---

## ‚úÖ Recomendaci√≥n: Modelo M√°s Grande Viable

### **llama3.1:8b** o **mistral:13b**

**llama3.1:8b** (Recomendado):
- ‚úÖ Tama√±o: ~4.7GB
- ‚úÖ RAM necesaria: ~6-8GB
- ‚úÖ Mejor rendimiento que llama3:8b
- ‚úÖ Calidad excelente
- ‚úÖ Funciona perfectamente con 15GB RAM

**mistral:13b** (Alternativa):
- ‚ö†Ô∏è Tama√±o: ~7.2GB
- ‚ö†Ô∏è RAM necesaria: ~10-12GB
- ‚ö†Ô∏è Funciona pero cerca del l√≠mite
- ‚úÖ Mejor calidad que modelos 7B
- ‚ö†Ô∏è Puede ser lento con 15GB RAM

---

## üéØ Instalaci√≥n de Modelos

### Instalar llama3.1:8b (Recomendado)

```bash
ollama pull llama3.1:8b
```

### Instalar mistral:13b (Alternativa)

```bash
ollama pull mistral:13b
```

### Ver modelos instalados

```bash
ollama list
```

---

## üìä Comparativa de Modelos

| Modelo | Tama√±o | RAM | Calidad | Velocidad | Recomendaci√≥n |
|--------|--------|-----|---------|-----------|---------------|
| llama3:8b | 4.7GB | 6-8GB | Buena | R√°pida | ‚úÖ Actual |
| llama3.1:8b | 4.7GB | 6-8GB | Excelente | R√°pida | ‚≠ê **Mejor opci√≥n** |
| mistral:7b | 4.1GB | 6-8GB | Buena | R√°pida | ‚úÖ Alternativa |
| mistral:13b | 7.2GB | 10-12GB | Excelente | Media | ‚ö†Ô∏è L√≠mite |
| llama3:70b | 40GB | 48-50GB | Superior | Muy lenta | ‚ùå No viable |

---

## üîß Configuraci√≥n en AuriPortal

Para cambiar el modelo de Ollama, edita `.env`:

```env
OLLAMA_MODEL=llama3.1:8b
```

O usa el modelo actual:

```env
OLLAMA_MODEL=llama3:latest
```

---

## üí° Recomendaci√≥n Final

**Para tu servidor con 15GB RAM:**

1. **Mejor opci√≥n**: `llama3.1:8b`
   - Mejor calidad que llama3:8b
   - Mismo tama√±o y requisitos
   - Excelente rendimiento

2. **Si necesitas m√°s calidad**: `mistral:13b`
   - Mejor calidad pero m√°s lento
   - Funciona pero cerca del l√≠mite
   - Solo si realmente necesitas m√°s calidad

3. **No recomendado**: Modelos 70B
   - Requieren 48-50GB RAM
   - No caben en tu servidor

---

**√öltima actualizaci√≥n**: Diciembre 2024



































